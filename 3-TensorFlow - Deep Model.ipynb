{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 建構簡單深度學習模型\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標\n",
    "* 使用tensorflow建構自己的`層 (layer)`\n",
    "* 使用`層 (layer)`建構深度網路  \n",
    "* 使用套件幫助自己進行模型檢測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 索引\n",
    "## [1 讀取資料](#1.-讀取資料)\n",
    "## [2 建立模型](#2.-建立模型)\n",
    "[2.1 層 Layer](#2.1-層-Layer)  \n",
    "[2.2 推測](#2.2-推測)  \n",
    "[2.3 誤差](#2.3-誤差)  \n",
    "[2.4 訓練](#2.4-訓練)  \n",
    "[2.5 評估](#2.5-評估)  \n",
    "[2.6 模型訓練](#2.6-模型訓練)  \n",
    "## [3 模型存取](#3.-模型存取)\n",
    "[3.1 Tensorflow模型文件](#3.1-Tensorflow模型文件)\n",
    "* [3.1.1 meta檔](#3.1.1-meta-檔)  \n",
    "* [3.1.2 index, data 檔](#3.1.2-index,-data-檔)  \n",
    "* [3.1.3 checkpoint 檔](#3.1.3-checkpoint-檔)  \n",
    "\n",
    "[3.2 保存模型](#3.2-保存模型)   \n",
    "[3.3 讀取模型](#3.3-讀取模型)\n",
    "* [3.3.1 讀圖](#3.3.1-讀圖)\n",
    "* [3.3.2 載參數](#3.3.2-載參數)\n",
    "\n",
    "## [4 模型檢測](#4.-模型存取)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 讀取資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上一章我們透過一大堆的操作，讀取並轉換我們的手寫數字資料集，讓我們得以丟進模型中訓練。  \n",
    "但是事實上，手寫數字作為一個新手入門最強大的數字集，google那幫人已經寫好了程式碼方便大家讀取。  \n",
    "在開始之前，還是要介紹一下手寫數字集的官網[Yann LeCun's website](http://yann.lecun.com/exdb/mnist/)。  整份資料被分為60000筆訓練資料, 10000筆測試資料, 由於需要驗證因此訓練集又被切出5000筆驗證資料。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "\n",
    "# 使用 input_data 的 read_data_sets() 方法, 指定資料集位置, 如果沒有會直接下載\n",
    "mnist = input_data.read_data_sets('datasets/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果大家有養成好習慣的話, 應該還是要如同上一章一樣做資料的檢查。  \n",
    "事實上我自己在使用時也是都有做的, 只是最後整理做成筆記本的時候拿掉了。  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 層 Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度網路, 顧名思義就是深度比別人深的神經網路.  \n",
    "如果在很複雜的模型中, 我們會把很多的`層 layer`放在一個`區塊 block`中.  \n",
    "但是這邊還不需要使用這種網路, 我們先學會如何設計一個`層 layer`.  \n",
    "首先要先了解有關於層的概念:  \n",
    "1. `層`是一個或多個神經元的組合\n",
    "2. `層`必須要搭配非線性的激活函數, 如`sigmoid`, `tenh`, `relu`等.\n",
    "3. `層`與`層`之間的連結是可以自己決定的, 可以跨`層`傳遞, 也可以不傳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(inputs, weight_shape, bias_shape):\n",
    "    '''定義一個 relu 層'''\n",
    "    \n",
    "    # 設定初始化方法, 由於 relu 的特性, 所以使用常態分配來初始化\n",
    "    w_init = tf.random_normal_initializer(stddev=(2.0/weight_shape[0])**0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    \n",
    "    # 定義每一層有 bias 個神經元\n",
    "    w = tf.get_variable('w', weight_shape, initializer=w_init)\n",
    "    b = tf.get_variable('b', bias_shape, initializer=bias_init)\n",
    "    \n",
    "    # 回傳使用 relu 運算\n",
    "    return tf.nn.relu( tf.matmul(inputs, w) + b )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 推測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    '''定義推測的步驟, 傳入一筆或多筆資料, 經過兩個隱藏層後, 直接輸出推測結果'''\n",
    "    \n",
    "    # 定義兩個隱藏層, 兩個隱藏層都有256個神經元, 與上一層全連結\n",
    "    # 特別使用 variable_scope 這個特殊的方法, 這在圖上可以清楚看到\n",
    "    # 後面會看到, 當我們要取得裡面的節點, 就需要加上這個變數區域\n",
    "    with tf.variable_scope('hidden_1'):\n",
    "        hidden_1 = layer(x, [784, 256], [256])\n",
    "    with tf.variable_scope('hidden_2'):\n",
    "        hidden_2 = layer(hidden_1, [256, 256], [256])\n",
    "        \n",
    "    # 定義一個輸出層, 與上一層全連結, 特別注意沒有softmax運算\n",
    "    with tf.variable_scope('output'):\n",
    "        output = layer(hidden_2, [256, 10], [10])\n",
    "        \n",
    "    return hidden_1, hidden_2, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    '''定義誤差函數計算的步驟, 這邊使用的是交叉嫡'''\n",
    "    \n",
    "    # 這個模型在這時候才使用 softmax 並進行交叉嫡運算\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y)    \n",
    "    \n",
    "    # 直接將所有的數字揉在一起做平均\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step, lr):   \n",
    "    '''定義訓練的步驟, 用梯度下降法'''\n",
    "    \n",
    "    # 紀錄過程\n",
    "    tf.summary.scalar('cost', cost)\n",
    "    \n",
    "    # 定義訓練的方法, 使用梯度下降法\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    \n",
    "    # 進行誤差最小化任務\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    \n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    '''定義評估的方式, 輸入標籤以及預測標籤, 輸出準確率'''\n",
    "    \n",
    "    # 找出標籤與預測標籤的最大信心水準, 比較是否相同\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    # 沿著 0 維度降維, 算出一個準確率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # 紀錄過程\n",
    "    tf.summary.scalar('validation_error', (1. - accuracy))\n",
    "    \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義模型所需參數\n",
    "lr = 0.01\n",
    "epochs = 150\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Train Error: 0.239745438099 Validation Error: 0.232599973679\n",
      "Epoch: 0002 Train Error: 0.200145483017 Validation Error: 0.192600011826\n",
      "Epoch: 0003 Train Error: 0.18594545126 Validation Error: 0.181599974632\n",
      "Epoch: 0004 Train Error: 0.178072750568 Validation Error: 0.170599997044\n",
      "Epoch: 0005 Train Error: 0.17199999094 Validation Error: 0.165799975395\n",
      "Epoch: 0006 Train Error: 0.166836380959 Validation Error: 0.160799980164\n",
      "Epoch: 0007 Train Error: 0.162345468998 Validation Error: 0.156400024891\n",
      "Epoch: 0008 Train Error: 0.158545434475 Validation Error: 0.154799997807\n",
      "Epoch: 0009 Train Error: 0.155963659286 Validation Error: 0.15340000391\n",
      "Epoch: 0010 Train Error: 0.153945446014 Validation Error: 0.150600016117\n",
      "Epoch: 0011 Train Error: 0.151018202305 Validation Error: 0.147800028324\n",
      "Epoch: 0012 Train Error: 0.148781836033 Validation Error: 0.147599995136\n",
      "Epoch: 0013 Train Error: 0.146472752094 Validation Error: 0.145799994469\n",
      "Epoch: 0014 Train Error: 0.145272731781 Validation Error: 0.143999993801\n",
      "Epoch: 0015 Train Error: 0.143672704697 Validation Error: 0.143199980259\n",
      "Epoch: 0016 Train Error: 0.141672730446 Validation Error: 0.140200018883\n",
      "Epoch: 0017 Train Error: 0.14067274332 Validation Error: 0.14099997282\n",
      "Epoch: 0018 Train Error: 0.139163613319 Validation Error: 0.138800024986\n",
      "Epoch: 0019 Train Error: 0.137927293777 Validation Error: 0.138400018215\n",
      "Epoch: 0020 Train Error: 0.137036383152 Validation Error: 0.137799978256\n",
      "Epoch: 0021 Train Error: 0.135563611984 Validation Error: 0.135999977589\n",
      "Epoch: 0022 Train Error: 0.134309113026 Validation Error: 0.135599970818\n",
      "Epoch: 0023 Train Error: 0.133090913296 Validation Error: 0.134599983692\n",
      "Epoch: 0024 Train Error: 0.132000029087 Validation Error: 0.133599996567\n",
      "Epoch: 0025 Train Error: 0.130999982357 Validation Error: 0.133400022984\n",
      "Epoch: 0026 Train Error: 0.130490899086 Validation Error: 0.131600022316\n",
      "Epoch: 0027 Train Error: 0.129872739315 Validation Error: 0.131600022316\n",
      "Epoch: 0028 Train Error: 0.128690898418 Validation Error: 0.130400002003\n",
      "Epoch: 0029 Train Error: 0.127509117126 Validation Error: 0.130999982357\n",
      "Epoch: 0030 Train Error: 0.127072751522 Validation Error: 0.129400014877\n",
      "Epoch: 0031 Train Error: 0.12632727623 Validation Error: 0.130599975586\n",
      "Epoch: 0032 Train Error: 0.125418186188 Validation Error: 0.129000008106\n",
      "Epoch: 0033 Train Error: 0.124800026417 Validation Error: 0.129599988461\n",
      "Epoch: 0034 Train Error: 0.124254524708 Validation Error: 0.126399993896\n",
      "Epoch: 0035 Train Error: 0.123581826687 Validation Error: 0.128000020981\n",
      "Epoch: 0036 Train Error: 0.123054563999 Validation Error: 0.126999974251\n",
      "Epoch: 0037 Train Error: 0.122618198395 Validation Error: 0.126800000668\n",
      "Epoch: 0038 Train Error: 0.121927261353 Validation Error: 0.126600027084\n",
      "Epoch: 0039 Train Error: 0.122090935707 Validation Error: 0.126600027084\n",
      "Epoch: 0040 Train Error: 0.120927274227 Validation Error: 0.126200020313\n",
      "Epoch: 0041 Train Error: 0.120636343956 Validation Error: 0.126200020313\n",
      "Epoch: 0042 Train Error: 0.119872748852 Validation Error: 0.124199986458\n",
      "Epoch: 0043 Train Error: 0.119509100914 Validation Error: 0.126399993896\n",
      "Epoch: 0044 Train Error: 0.119036376476 Validation Error: 0.125\n",
      "Epoch: 0045 Train Error: 0.118654549122 Validation Error: 0.124400019646\n",
      "Epoch: 0046 Train Error: 0.118072748184 Validation Error: 0.125\n",
      "Epoch: 0047 Train Error: 0.117999970913 Validation Error: 0.124599993229\n",
      "Epoch: 0048 Train Error: 0.117145478725 Validation Error: 0.123799979687\n",
      "Epoch: 0049 Train Error: 0.117327272892 Validation Error: 0.123199999332\n",
      "Epoch: 0050 Train Error: 0.116709113121 Validation Error: 0.124599993229\n",
      "Epoch: 0051 Train Error: 0.115872740746 Validation Error: 0.124400019646\n",
      "Epoch: 0052 Train Error: 0.115981817245 Validation Error: 0.123199999332\n",
      "Epoch: 0053 Train Error: 0.115218162537 Validation Error: 0.12239998579\n",
      "Epoch: 0054 Train Error: 0.114890933037 Validation Error: 0.121800005436\n",
      "Epoch: 0055 Train Error: 0.114581823349 Validation Error: 0.123000025749\n",
      "Epoch: 0056 Train Error: 0.114490926266 Validation Error: 0.120999991894\n",
      "Epoch: 0057 Train Error: 0.113909065723 Validation Error: 0.122200012207\n",
      "Epoch: 0058 Train Error: 0.113472700119 Validation Error: 0.121999979019\n",
      "Epoch: 0059 Train Error: 0.113200008869 Validation Error: 0.120999991894\n",
      "Epoch: 0060 Train Error: 0.113072752953 Validation Error: 0.121399998665\n",
      "Epoch: 0061 Train Error: 0.112800002098 Validation Error: 0.121200025082\n",
      "Epoch: 0062 Train Error: 0.112690925598 Validation Error: 0.122600018978\n",
      "Epoch: 0063 Train Error: 0.112472712994 Validation Error: 0.121599972248\n",
      "Epoch: 0064 Train Error: 0.112200021744 Validation Error: 0.120199978352\n",
      "Epoch: 0065 Train Error: 0.111763656139 Validation Error: 0.121399998665\n",
      "Epoch: 0066 Train Error: 0.111490905285 Validation Error: 0.121399998665\n",
      "Epoch: 0067 Train Error: 0.11121815443 Validation Error: 0.120400011539\n",
      "Epoch: 0068 Train Error: 0.111181795597 Validation Error: 0.120400011539\n",
      "Epoch: 0069 Train Error: 0.110763609409 Validation Error: 0.120000004768\n",
      "Epoch: 0070 Train Error: 0.11038184166 Validation Error: 0.121200025082\n",
      "Epoch: 0071 Train Error: 0.110309064388 Validation Error: 0.120599985123\n",
      "Epoch: 0072 Train Error: 0.110127270222 Validation Error: 0.119799971581\n",
      "Epoch: 0073 Train Error: 0.109981834888 Validation Error: 0.120800018311\n",
      "Epoch: 0074 Train Error: 0.109672725201 Validation Error: 0.120199978352\n",
      "Epoch: 0075 Train Error: 0.10932725668 Validation Error: 0.119599997997\n",
      "Epoch: 0076 Train Error: 0.10910910368 Validation Error: 0.119799971581\n",
      "Epoch: 0077 Train Error: 0.109036386013 Validation Error: 0.120000004768\n",
      "Epoch: 0078 Train Error: 0.108581840992 Validation Error: 0.120400011539\n",
      "Epoch: 0079 Train Error: 0.108727276325 Validation Error: 0.119599997997\n",
      "Epoch: 0080 Train Error: 0.108090937138 Validation Error: 0.119599997997\n",
      "Epoch: 0081 Train Error: 0.108290910721 Validation Error: 0.120400011539\n",
      "Epoch: 0082 Train Error: 0.107927262783 Validation Error: 0.119000017643\n",
      "Epoch: 0083 Train Error: 0.107472717762 Validation Error: 0.119199991226\n",
      "Epoch: 0084 Train Error: 0.107236385345 Validation Error: 0.119599997997\n",
      "Epoch: 0085 Train Error: 0.107309103012 Validation Error: 0.120400011539\n",
      "Epoch: 0086 Train Error: 0.107127249241 Validation Error: 0.119199991226\n",
      "Epoch: 0087 Train Error: 0.106836378574 Validation Error: 0.119199991226\n",
      "Epoch: 0088 Train Error: 0.106709063053 Validation Error: 0.119000017643\n",
      "Epoch: 0089 Train Error: 0.106636345387 Validation Error: 0.119000017643\n",
      "Epoch: 0090 Train Error: 0.106527268887 Validation Error: 0.119799971581\n",
      "Epoch: 0091 Train Error: 0.106127262115 Validation Error: 0.118799984455\n",
      "Epoch: 0092 Train Error: 0.106000006199 Validation Error: 0.119199991226\n",
      "Epoch: 0093 Train Error: 0.106127262115 Validation Error: 0.120000004768\n",
      "Epoch: 0094 Train Error: 0.105618178844 Validation Error: 0.119199991226\n",
      "Epoch: 0095 Train Error: 0.105581820011 Validation Error: 0.119400024414\n",
      "Epoch: 0096 Train Error: 0.105436384678 Validation Error: 0.119400024414\n",
      "Epoch: 0097 Train Error: 0.105163633823 Validation Error: 0.119400024414\n",
      "Epoch: 0098 Train Error: 0.105109095573 Validation Error: 0.119199991226\n",
      "Epoch: 0099 Train Error: 0.105272710323 Validation Error: 0.119199991226\n",
      "Epoch: 0100 Train Error: 0.10523635149 Validation Error: 0.119199991226\n",
      "Epoch: 0101 Train Error: 0.10496366024 Validation Error: 0.119599997997\n",
      "Epoch: 0102 Train Error: 0.104727268219 Validation Error: 0.119799971581\n",
      "Epoch: 0103 Train Error: 0.104636371136 Validation Error: 0.118799984455\n",
      "Epoch: 0104 Train Error: 0.104745447636 Validation Error: 0.119000017643\n",
      "Epoch: 0105 Train Error: 0.104563653469 Validation Error: 0.119199991226\n",
      "Epoch: 0106 Train Error: 0.104436337948 Validation Error: 0.119199991226\n",
      "Epoch: 0107 Train Error: 0.104127287865 Validation Error: 0.119000017643\n",
      "Epoch: 0108 Train Error: 0.104090929031 Validation Error: 0.119000017643\n",
      "Epoch: 0109 Train Error: 0.103999972343 Validation Error: 0.118600010872\n",
      "Epoch: 0110 Train Error: 0.103836357594 Validation Error: 0.119400024414\n",
      "Epoch: 0111 Train Error: 0.10379999876 Validation Error: 0.118799984455\n",
      "Epoch: 0112 Train Error: 0.103545427322 Validation Error: 0.119000017643\n",
      "Epoch: 0113 Train Error: 0.103654563427 Validation Error: 0.119199991226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0114 Train Error: 0.103472709656 Validation Error: 0.118799984455\n",
      "Epoch: 0115 Train Error: 0.103454530239 Validation Error: 0.119000017643\n",
      "Epoch: 0116 Train Error: 0.103363633156 Validation Error: 0.118799984455\n",
      "Epoch: 0117 Train Error: 0.103236377239 Validation Error: 0.118799984455\n",
      "Epoch: 0118 Train Error: 0.103236377239 Validation Error: 0.119199991226\n",
      "Epoch: 0119 Train Error: 0.103018164635 Validation Error: 0.119199991226\n",
      "Epoch: 0120 Train Error: 0.102872729301 Validation Error: 0.118600010872\n",
      "Epoch: 0121 Train Error: 0.102727293968 Validation Error: 0.118600010872\n",
      "Epoch: 0122 Train Error: 0.102945446968 Validation Error: 0.118799984455\n",
      "Epoch: 0123 Train Error: 0.10258179903 Validation Error: 0.118600010872\n",
      "Epoch: 0124 Train Error: 0.10263633728 Validation Error: 0.118200004101\n",
      "Epoch: 0125 Train Error: 0.102509081364 Validation Error: 0.119199991226\n",
      "Epoch: 0126 Train Error: 0.102400004864 Validation Error: 0.118600010872\n",
      "Epoch: 0127 Train Error: 0.102563619614 Validation Error: 0.119400024414\n",
      "Epoch: 0128 Train Error: 0.102400004864 Validation Error: 0.118600010872\n",
      "Epoch: 0129 Train Error: 0.102327287197 Validation Error: 0.118600010872\n",
      "Epoch: 0130 Train Error: 0.10225456953 Validation Error: 0.118399977684\n",
      "Epoch: 0131 Train Error: 0.102163612843 Validation Error: 0.118600010872\n",
      "Epoch: 0132 Train Error: 0.102109074593 Validation Error: 0.11779999733\n",
      "Epoch: 0133 Train Error: 0.102090895176 Validation Error: 0.119000017643\n",
      "Epoch: 0134 Train Error: 0.102199971676 Validation Error: 0.118399977684\n",
      "Epoch: 0135 Train Error: 0.102018177509 Validation Error: 0.118799984455\n",
      "Epoch: 0136 Train Error: 0.101890921593 Validation Error: 0.119400024414\n",
      "Epoch: 0137 Train Error: 0.101781845093 Validation Error: 0.118399977684\n",
      "Epoch: 0138 Train Error: 0.101763665676 Validation Error: 0.118600010872\n",
      "Epoch: 0139 Train Error: 0.101745426655 Validation Error: 0.118399977684\n",
      "Epoch: 0140 Train Error: 0.101727247238 Validation Error: 0.119400024414\n",
      "Epoch: 0141 Train Error: 0.101818203926 Validation Error: 0.119000017643\n",
      "Epoch: 0142 Train Error: 0.101563632488 Validation Error: 0.117999970913\n",
      "Epoch: 0143 Train Error: 0.101599991322 Validation Error: 0.119000017643\n",
      "Epoch: 0144 Train Error: 0.101490914822 Validation Error: 0.118600010872\n",
      "Epoch: 0145 Train Error: 0.101618170738 Validation Error: 0.118399977684\n",
      "Epoch: 0146 Train Error: 0.101454555988 Validation Error: 0.117999970913\n",
      "Epoch: 0147 Train Error: 0.101509094238 Validation Error: 0.118399977684\n",
      "Epoch: 0148 Train Error: 0.101418197155 Validation Error: 0.118399977684\n",
      "Epoch: 0149 Train Error: 0.101236343384 Validation Error: 0.117999970913\n",
      "Epoch: 0150 Train Error: 0.101290881634 Validation Error: 0.118799984455\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.8845\n"
     ]
    }
   ],
   "source": [
    "# 開啟新的圖(graph), 這樣會在結束運算後自動關閉\n",
    "# 僅因測試使用, 方便釋放資源以及模型自動清空, 重新執行才不會出現已經存在的錯誤\n",
    "# 如果需要保存變數資料, 請不要使用這個語法\n",
    "with tf.Graph().as_default() as g:\n",
    "    # 設定 x, y 的佔位符, 這樣可以因應不同情況做替換\n",
    "    x = tf.placeholder('float', [None, 784], name='x')\n",
    "    y = tf.placeholder('float', [None, 10], name='y')\n",
    "\n",
    "    # 初始化從零開始, 計算目前訓練的次數\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    # 呼叫上方定義的四個模型組成要素\n",
    "    hidden_1, hidden_2, output = inference(x)\n",
    "    cost = loss(output, y)\n",
    "    train_op = training(cost, global_step, lr)\n",
    "    eval_op = evaluate(output, y)\n",
    "\n",
    "    # 設定儲存節點跟目標資料夾\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver(max_to_keep=1) # 只保留最後一筆記錄檔\n",
    "    summary_writer = tf.summary.FileWriter('logs/ml_logs', graph=g) \n",
    "\n",
    "    # 開啟會話, 進行變數的初始化.\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # 開始訓練, 這個迴圈會重複進行直到訓練結束\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # 由於是小批次訓練, 這邊設定了每個epoch會更新的次數\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            # 呼叫上方定義的小批次傳入方法, 取得當前的 (x, y)\n",
    "            mbatch_x, mbatch_y = mnist.train.next_batch(batch_size)\n",
    "            # 由會話開啟訓練, 由於我們使用了placeholder, 所以feed_dict是一定要給的\n",
    "            sess.run(train_op, feed_dict={x:mbatch_x, y:mbatch_y})\n",
    "\n",
    "        # 呼叫評估方法, 計算出train, val的準確度, 印出誤差\n",
    "        train_accuracy = sess.run(eval_op, feed_dict={x:mnist.train.images, y:mnist.train.labels})\n",
    "        val_accuracy = sess.run(eval_op, feed_dict={x:mnist.validation.images, y:mnist.validation.labels})\n",
    "        print('Epoch:', '%04d' % (epoch+1), 'Train Error:', (1-train_accuracy), 'Validation Error:', (1-val_accuracy))\n",
    "\n",
    "        # 執行我們設定的紀錄節點, 並把結果寫到指定的資料夾\n",
    "        summary_str = sess.run(summary_op, feed_dict={x:mbatch_x, y:mbatch_y})\n",
    "        summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "        saver.save(sess, 'logs/ml_logs/model-checkpoint', global_step=global_step)\n",
    "\n",
    "    # 結束\n",
    "    print('Optimization Finished!')\n",
    "\n",
    "    # 呼叫評估方法, 計算test資料準確度並印出\n",
    "    accuracy = sess.run(eval_op, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "    print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們現在訓練完成了, 狀態好的話應該是可以得到在測試資料中有將近98%的準確率的模型.  \n",
    "如果跑出來結果很差, 只有70%或80%的話, 多試幾次應該就可以.  \n",
    "會有這個問題一方面是因為我們使用了很簡單的梯度下降, 如果誤差曲面很平緩, 就會造成參數沒辦法收斂.  \n",
    "當然還有另外一個問題就是我們訓練次數設太少了, 我有點偷懶所以只訓練100次, 還把學習速率稍微調高了.  \n",
    "這兩個問題暫時先擺著, 這是為了能夠快速進行這個教程演示.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型存取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在tensorflow養成過程中, 我們有時候需要使用別人訓練好的模型, 稱作`pretrained model`.  \n",
    "或是我們模型訓練好, 還需要做其他的處理或是取得其中權重等動作.  \n",
    "因此我們需要了解tensorflow怎麼保存我們訓練好的模型數據."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Tensorflow模型文件\n",
    "由於我們有在訓練中持續保存模型, 我們現在可以打開 checkpoint_dir 目錄.  \n",
    "可以看到以下幾個模型保存的內容（如果存檔的參數都跟我設定一樣的話）：\n",
    "* checkpoint\n",
    "* model-checkpoint.meta\n",
    "* model-checkpoint.index\n",
    "* model-checkpoint.data-00000-of-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 meta 檔\n",
    "meta文件是保存圖的結構, 包含變量, op, 集合等."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 index, data 檔\n",
    "這兩個檔案是模型檔, 二進制文件, 保存了權重、神經元、梯度等變量。  \n",
    "在tensorflow 0.11版之前, 保存在.ckpt文件中。  \n",
    "在新版中, 改為通過兩個文件保存。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 checkpoint 檔\n",
    "這是訓練紀錄檔, 或者我們可以認為這是版本紀錄檔, 它map不同時期的模型其對應的模型檔.    \n",
    "也就是我們在`inference`的時候, 可以透過修改這個檔案, 指定使用什麼時候的model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 保存模型\n",
    "tensorflow 提供了 `tf.train.Saver` 來保存模型.  \n",
    "要特別注意, tensorflow 將變量存放於 `Session` 中.  \n",
    "也就是說當我們使用 `with` 寫法, 一旦離開了 `Session` 環境, 變數就隨風東流了.  \n",
    "所以如果前面的語法中省略了保存動作, 現在想要拿到同樣的模型, 是不可能了QQ.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於剛剛我們確實有仔細的存出我們的模型, 因此現在就只需要展示程式碼就好囉.  \n",
    "`saver = tf.train.Saver()`  \n",
    "`saver.save(sess, 'ml_logs/model-checkpoint', global_step=global_step)`  \n",
    "這是我們剛剛主要使用的程式碼, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在實際使用時, 我們可能要持續保存模型, 但是由於圖是不變的, 可以通過下面方式設定不保存圖：  \n",
    "`saver.save(sess, 'ml_logs/model-checkpoint',\n",
    "                   global_step=global_step,\n",
    "                   write_meta_graph=False)`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "還有一種也很實用的方式, 如果我們希望每小時保存一次模型, 且只保留最近的5個模型：   \n",
    "`tf.train.Saver(max_to_keep=5, keep_checkpoint_every_n_hours=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 讀取模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在前面我們提到, tensorflow將模型數據分開保存為不同的檔案.  \n",
    "因此, 我們在讀取模型的時候也要分為兩步讀取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 讀圖\n",
    "既然模型已經存下了圖的結構, 那麼我們可以使用下方的程式碼直接將圖讀出就好.  \n",
    "比較怕存的時候沒有存到圖, 這一定要特別小心, 建議跑完訓練後都要檢查一下目錄.  \n",
    "\n",
    "`saver = tf.train.import_meta_graph('ml_logs/model-checkpoint-42900.meta')`\n",
    "\n",
    "執行上方程式碼後, 我們就順利把圖讀進來了.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 載參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "僅僅只有圖沒有用, 我們模型更重要的是其中保存的參數.  \n",
    "上方也特別提到, 變數值的存放需要仰賴`Session`.  \n",
    "因此我們要先創建好`Session`, 才能載入參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from logs/ml_logs\\model-checkpoint-64350\n"
     ]
    }
   ],
   "source": [
    "# 創建會話, 還是要注意這種寫法需要手動關閉才能釋放資源\n",
    "sess = tf.Session()\n",
    "\n",
    "# 讀取圖\n",
    "saver = tf.train.import_meta_graph('logs/ml_logs/model-checkpoint-64350.meta')\n",
    "\n",
    "# 讀取權重\n",
    "saver.restore(sess, tf.train.latest_checkpoint('logs/ml_logs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "執行上方的程式碼, 我們可以看到 tensorflow 告訴我們成功讀取了權重.  \n",
    "這時候我們就可以開始拿出模型的權重了.  \n",
    "開始之前通常都要完成下面的動作, 可以當作例行公事處理.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這個動作是將現在預設的圖放到python變數'g'(注意不是tensorflow變數)\n",
    "g = tf.get_default_graph()\n",
    "\n",
    "# 由於 placeholder 我們需要隨時給值, 所以把它們取出準備放不同的值\n",
    "# 注意名稱, 使用的是我們放在 tf.placeholder() 裡面的參數 name='?'\n",
    "# 這個名稱是唯一且不重複的, 為了讓我們命名不受限制, tensorflow 會自動加上索引\n",
    "x = g.get_tensor_by_name('x:0')\n",
    "y = g.get_tensor_by_name('y:0')\n",
    "\n",
    "# 設定 feed 字典\n",
    "feed_dict={x:mnist.test.images, y:mnist.test.labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成後, 我們就可以對模型做任何想做的事情了~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88450003"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我們可以丟新的資料給模型預測\n",
    "\n",
    "# 拿到預測的節點\n",
    "# 注意名稱, 由於這個節點我們並沒有命名\n",
    "# tensorflow會自動命名, 要拿到名稱要看圖, 所以 tensorboard 還是很重要的.\n",
    "accuracy = g.get_tensor_by_name('Mean_1:0')\n",
    "# 運用會話, 執行節點, 塞入test資料, 跟剛剛的結果是一樣的~~\n",
    "sess.run(accuracy, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我們可以拿到任何隱藏層的輸出\n",
    "\n",
    "# 拿到第一個隱藏層的輸出\n",
    "# 注意名稱, 我們在 inference 的時候給了它變數區域, 因此要存取也要加上.\n",
    "h1 = g.get_tensor_by_name('hidden_1/Relu:0')\n",
    "\n",
    "# 運用會話, 執行節點, 塞入test資料\n",
    "# 可以看到輸出的 tensor.shape 是 [datas, 256] 的形狀, 不是一開始資料的 [datas, 784]\n",
    "sess.run(h1, feed_dict).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當然, 既然我們可以存取, 就意味著我們可以修改.  \n",
    "我們可以設計新的運算加入圖中, 這就是`pretrained model`的概念.  \n",
    "我們拿到已經訓練完畢的模型, 可能從某個節點改變其運作方向, 加入自己的設計.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型檢測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上一章我們並沒有寫上模型的檢測.  \n",
    "最主要是一開始使用的是沒有隱藏層的簡單模型, 並不能深刻的了解深度學習到底在深什麼.  \n",
    "再加上上一章已經有了資料處理(雖然是很基礎的), 實在不想全都塞在同一個筆記本裡.  \n",
    "因此一直到這裡我們才進行真正的模型檢測.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = g.get_tensor_by_name('output/Relu:0')\n",
    "y_pred = sess.run(output, feed_dict).argmax(axis=-1)\n",
    "y_true = mnist.test.labels.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn 的分類報告, F1分數, 混淆矩陣\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.52      0.68      1881\n",
      "          1       0.99      0.99      0.99      1137\n",
      "          2       0.98      0.97      0.97      1045\n",
      "          3       0.98      0.96      0.97      1030\n",
      "          4       0.98      0.97      0.97       992\n",
      "          5       0.97      0.96      0.96       902\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.97      0.98      0.97      1019\n",
      "          8       0.97      0.97      0.97       980\n",
      "          9       0.97      0.97      0.97      1014\n",
      "\n",
      "avg / total       0.98      0.88      0.92     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_pred, y_true) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們特地使用sklearn的評價報告, 這個報告我們要輸入`估計值`, `實際值`, `類別`.  \n",
    "由於我們的類別就是0~9, 所以就直接省下了類別, 報告內容如下：  \n",
    "1. 精確度 precision: 判斷為該類別中真正為該類別的比例\n",
    "2. 召回率 recall: 真正在該類別中被正確分類的比例\n",
    "3. f1-score: 綜合精確度與召回率的調和值\n",
    "4. support: 該資料集中該類的數量\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 971    1    4    0    2    5  891    0    5    2]\n",
      " [   0 1124    1    0    0    0    4    5    0    3]\n",
      " [   1    2 1010    6    7    0    9    7    2    1]\n",
      " [   2    1    3  990    0   12    2    7    7    6]\n",
      " [   1    0    3    0  961    2   13    2    3    7]\n",
      " [   2    2    0    4    0  864   26    0    3    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    1    6    4    2    1    3  996    3    2]\n",
      " [   1    4    5    4    0    4    9    1  947    5]\n",
      " [   1    0    0    2   10    4    1   10    4  982]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2bd2317d160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用估計值和真實值製作混淆矩陣\n",
    "mat = confusion_matrix(y_pred, y_true)\n",
    "print(mat)\n",
    "# 用熱點圖可以清楚看出混淆矩陣的分布\n",
    "sns.heatmap(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們透過混淆矩陣, 可以確認是不是有某一種類別分類特別不好.  \n",
    "不過, 混淆矩陣並不能很好的表達到底模型好或不好, 真的很混淆.  \n",
    "所以通常我們都會使用`分類報告 classification report`.  \n",
    "實務上我們可能會特別重視分類是否正確(或錯誤), 因此可能需要調整`f1-score`計算.  \n",
    "不過那太複雜了, 之後有碰到在寫.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要記得關掉會話哦~\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
